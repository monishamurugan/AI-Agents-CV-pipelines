{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d166663-418c-481b-a5d4-8ddf3fcf8616",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LLM-Powered AI Agents for Building and Validating Computer Vision Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb24d6c6-3c12-42b5-918d-fc81a3a1732e",
   "metadata": {},
   "source": [
    "## Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33384789-2c89-46f4-be8a-86512c24811f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U pynvml bitsandbytes transformers peft accelerate datasets scipy einops evaluate trl rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa100bd-e3ee-48dc-ad5e-0e4eb65d1c08",
   "metadata": {},
   "source": [
    "## Loading the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdbbd90b-81ae-4a77-8247-dda29f3ca32a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    GenerationConfig,\n",
    "    set_seed\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from trl import SFTTrainer\n",
    "from huggingface_hub import interpreter_login\n",
    "from pynvml import *\n",
    "from functools import partial\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc48c7c9-f814-42db-b7d9-be1faced1561",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# disable Weights and Biases\n",
    "os.environ['WANDB_DISABLED']=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9879d8dd-e13c-4d01-913a-a4a190874c22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your token (input will not be visible):  ········\n",
      "Add token as git credential? (Y/n)  n\n"
     ]
    }
   ],
   "source": [
    "# hugging face login\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a49500-9984-4d3f-a003-04886630e90b",
   "metadata": {},
   "source": [
    "## GPU Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d4c36fd-e58a-433c-bb04-fd1fb35096db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ee265-202f-4b57-9ebf-1670bf0987fa",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c0642ce-ec32-4bc7-bf35-3c184060f8d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./cva_gstreamer_pipeline_dataset_V1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eca1e58c-1197-4ed4-b078-4ba2fa4c6972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd431990-d1d1-49e0-8c97-e3e8cf20cadd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '{\"source_type\": \"rtsp\", \"source_location\": \"rtsp://192.168.1.124:8069/preview\", \"video_scale\": {\"width\": 1597, \"height\": 518}, \"caps_filter\": \"GBR\", \"detect\": {\"model\": \"/usr/share/models/onnx/detection/1.0/FP32/model_8007.xml\", \"device\": \"HDDL\"}, \"track\": {\"tracking_type\": 0}, \"classify\": {\"model\": \"/opt/models/intel/segmentation/2.0/FP32/model_3695.xml\", \"device\": \"GPU\", \"inference_region\": \"full-frame\", \"model_proc\": \"/home/user/.local/intel/model_proc/detection/model_3956.json\"}, \"inference\": [{\"model\": \"/home/user/.local/models/intel/classification/5.0/FP32/model_5775.xml\", \"device\": \"CPU\", \"inference_region\": \"roi-list\"}, {\"model\": \"/usr/share/models/onnx/recognition/2.1/FP16/model_7317.xml\", \"device\": \"HDDL\", \"inference_region\": \"roi-list\"}, {\"model\": \"/opt/models/intel/detection/3.0/FP16/model_9971.xml\", \"device\": \"CPU\", \"inference_region\": \"roi-list\"}, {\"model\": \"/usr/share/models/intel/segmentation/5.0/INT8/model_6368.xml\", \"device\": \"CPU\", \"inference_region\": \"roi-list\"}], \"emit_signals\": true, \"sync\": false, \"drop\": true, \"max_buffers\": 500}',\n",
       " 'pipeline': 'gst-launch-1.0 rtspsrc location=rtsp://192.168.1.124:8069/preview ! rtph264depay ! h264parse ! avdec_h264 ! videoconvert ! capsfilter caps=video/x-raw,format=GBR ! videoscale ! video/x-raw,width=1597,height=518 ! gvadetect model=/usr/share/models/onnx/detection/1.0/FP32/model_8007.xml device=HDDL ! queue ! gvatrack tracking-type=0 ! queue ! gvaclassify model=/opt/models/intel/segmentation/2.0/FP32/model_3695.xml device=GPU inference-region=full-frame model-proc=/home/user/.local/intel/model_proc/detection/model_3956.json ! queue ! gvainference model=/home/user/.local/models/intel/classification/5.0/FP32/model_5775.xml device=CPU inference-region=roi-list ! queue ! gvainference model=/usr/share/models/onnx/recognition/2.1/FP16/model_7317.xml device=HDDL inference-region=roi-list ! queue ! gvainference model=/opt/models/intel/detection/3.0/FP16/model_9971.xml device=CPU inference-region=roi-list ! queue ! gvainference model=/usr/share/models/intel/segmentation/5.0/INT8/model_6368.xml device=CPU inference-region=roi-list ! queue ! appsink name=appsink emit-signals=True drop=True sync=False max-buffers=500'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de5b68-f4c2-4de0-bb91-9f3ff7a9400a",
   "metadata": {},
   "source": [
    "## Test Train Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe46a9d-dd69-4ab9-9cce-456b7f26e76e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_test = dataset.train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "497b5b57-75e8-4f10-8aff-f520871aa268",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_validation = train_test['test'].train_test_split(test_size=0.5, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0658e2f2-ddd7-4ce8-9544-0e55d180f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    \"train\": train_test['train'],\n",
    "    \"test\": test_validation['test'],\n",
    "    \"validation\": test_validation['train']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8770f708-4ba8-4b11-b68e-05e93cf3f616",
   "metadata": {},
   "source": [
    "## Create Bitsandbytes configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0d9be58-612f-4198-8cd0-684dc45712c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "    )\n",
    "\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b6a904-b792-4018-a4f8-610b0332412b",
   "metadata": {},
   "source": [
    "## Loading the Pre-Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19e6f8ad-f7d9-4f82-bdad-5c2447ef6f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a537fb6fee494ba931f97427c7157e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='microsoft/phi-2'\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                                      device_map=device_map,\n",
    "                                                      quantization_config=bnb_config,\n",
    "                                                      trust_remote_code=True,\n",
    "                                                      use_auth_token=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2941a9-2c92-4abc-b045-c7ae22009489",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e23d5e1b-0b72-4416-aa07-e67cd47e010e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True,padding_side=\"left\",add_eos_token=True,add_bos_token=True,use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fb57fad-d909-4d1e-9631-6f99dad881d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_tokenizer = AutoTokenizer.from_pretrained(model_name, add_bos_token=True, trust_remote_code=True, use_fast=False)\n",
    "eval_tokenizer.pad_token = eval_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49ef7912-9218-4142-a60c-50c45af9cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_from_model(model,prompt):\n",
    "    toks = eval_tokenizer(prompt, return_tensors=\"pt\")\n",
    "    res = model.generate(**toks.to(\"cuda\"), max_new_tokens=1000, do_sample=True,num_return_sequences=1,temperature=0.1,num_beams=1,top_p=0.95,).to('cpu')\n",
    "    return eval_tokenizer.batch_decode(res,skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfb8b6d-312c-491c-896f-51771ab83485",
   "metadata": {},
   "source": [
    "## Test the Model with Zero Shot Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "748c6941-b9b4-49bf-a5cb-791feabfac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formatted_prompt(prompt):\n",
    "    return f\"Task: Convert the JSON configuration below into a valid gst-launch-1.0 pipeline command. Ensure all elements and properties are properly formatted.\\nInput JSON:\\n{prompt}\\nOutput:\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49e68710-8ef6-4826-a8f5-0de5c902fb22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Task: Convert the JSON configuration below into a valid gst-launch-1.0 pipeline command. Ensure all elements and properties are properly formatted.\n",
      "Input JSON:\n",
      "{\"source_type\": \"file\", \"source_location\": \"/opt/warehouse_8/aisle/sensor_3.mp4\", \"video_crop\": {\"top\": 496, \"left\": 71, \"right\": 67, \"bottom\": 129}, \"caps_filter\": \"NV12_16L32S\", \"frame_rate\": \"50/2\", \"detect\": {\"model\": \"/usr/local/models/onnx/detection/3.0/INT8/model_9162.xml\", \"device\": \"HDDL\", \"threshold\": 0.76}, \"track\": {\"tracking_type\": \"zero-term-imageless\"}, \"emit_signals\": false, \"sync\": false, \"drop\": true}\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "GROUND TRUTH:\n",
      "gst-launch-1.0 filesrc location=/opt/warehouse_8/aisle/sensor_3.mp4 ! decodebin ! videoconvert ! videorate ! video/x-raw,framerate=50/2 ! videoconvert ! capsfilter caps=video/x-raw,format=NV12_16L32S ! videocrop top=496 left=71 right=67 bottom=129 ! queue ! gvadetect model=/usr/local/models/onnx/detection/3.0/INT8/model_9162.xml device=HDDL threshold=0.76 ! queue ! gvatrack tracking-type=zero-term-imageless ! queue ! appsink name=appsink emit-signals=False drop=True sync=False\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "gst-launch-1.0 -s source_type=file -s source_location=/opt/warehouse_8/aisle/sensor_3.mp4 -s video_crop={\"top\": 496, \"left\": 71, \"right\": 67, \"bottom\": 129} -s caps_filter=NV12_16L32S -s frame_rate=50/2 -s detect={\"model\": \"/usr/local/models/onnx/detection/3.0/INT8/model_9162.xml\", \"device\": \"HDDL\", \"threshold\": 0.76} -s track={\"tracking_type\": \"zero-term-imageless\"} -s emit_signals=false -s sync=false -s drop=true\n",
      "\n",
      "CPU times: user 6.01 s, sys: 238 ms, total: 6.24 s\n",
      "Wall time: 6.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "index = 10\n",
    "\n",
    "sample_prompt = dataset['test'][index]['prompt']\n",
    "sample_pipeline = dataset['test'][index]['pipeline']\n",
    "\n",
    "formatted_prompt = get_formatted_prompt(sample_prompt)\n",
    "res = generate_text_from_model(base_model,formatted_prompt)\n",
    "output = res[0].split('Output:\\n')[1]\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{formatted_prompt}')\n",
    "print(dash_line)\n",
    "print(f'GROUND TRUTH:\\n{sample_pipeline}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6145ae-5a6e-442e-8f5e-453b665cece3",
   "metadata": {},
   "source": [
    "## Pre-processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1a94805-cfdd-47dc-b076-b8751b670cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_prompt_formats(sample):\n",
    "    \"\"\"\n",
    "    Format various fields of the sample ('instruction','output')\n",
    "    Then concatenate them using two newline characters \n",
    "    :param sample: Sample dictionnary\n",
    "    \"\"\"\n",
    "    INTRO_BLURB = \"This tool generates GStreamer pipeline commands from JSON configurations. Follow the input format to create valid gst-launch-1.0 commands.\"\n",
    "    INSTRUCTION_KEY = \"### Instruct: Convert the JSON configuration below into a valid gst-launch-1.0 pipeline command. Ensure all elements and properties are properly formatted.\"\n",
    "    RESPONSE_KEY = \"### Output:\"\n",
    "    END_KEY = \"### End\"\n",
    "    \n",
    "    blurb = f\"\\n{INTRO_BLURB}\"\n",
    "    instruction = f\"{INSTRUCTION_KEY}\"\n",
    "    input_context = f\"{sample['prompt']}\" if sample[\"prompt\"] else None\n",
    "    response = f\"{RESPONSE_KEY}\\n{sample['pipeline']}\"\n",
    "    end = f\"{END_KEY}\"\n",
    "    \n",
    "    parts = [part for part in [blurb, instruction, input_context, response, end] if part]\n",
    "\n",
    "    sample[\"text\"] = \"\\n\\n\".join(parts)\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bb43e54-702a-49ea-a863-dcb514e8cf61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_max_length(model):\n",
    "    conf = model.config\n",
    "    max_length = None\n",
    "    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n",
    "        max_length = getattr(model.config, length_setting, None)\n",
    "        if max_length:\n",
    "            print(f\"Found max lenth: {max_length}\")\n",
    "            break\n",
    "    if not max_length:\n",
    "        max_length = 1024\n",
    "        print(f\"Using default max length: {max_length}\")\n",
    "    return max_length\n",
    "\n",
    "\n",
    "def preprocess_batch(batch, tokenizer, max_length):\n",
    "    \"\"\"\n",
    "    Tokenizing a batch\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98b0f1d5-ad1b-44a6-824e-b77a8f8da81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(tokenizer: AutoTokenizer, max_length: int, seed, dataset):\n",
    "    \"\"\"Format & tokenize it so it is ready for training\n",
    "    :param tokenizer (AutoTokenizer): Model Tokenizer\n",
    "    :param max_length (int): Maximum number of tokens to emit from tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add prompt to each sample\n",
    "    print(\"Preprocessing dataset...\")\n",
    "    dataset = dataset.map(create_prompt_formats) #, batched=True)\n",
    "    \n",
    "    _preprocessing_function = partial(preprocess_batch, max_length=max_length, tokenizer=tokenizer)\n",
    "    \n",
    "    dataset = dataset.map(\n",
    "        _preprocessing_function,\n",
    "        batched=True\n",
    "    )\n",
    "\n",
    "    # Filter out samples that have input_ids exceeding max_length\n",
    "    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n",
    "    \n",
    "    # Shuffle dataset\n",
    "    dataset = dataset.shuffle(seed=seed)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b9910cd-f599-4ce4-ac70-30d908513c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 2631 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a22f88eb-af6b-4ec4-9f09-5ce1cfaba9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found max lenth: 2048\n",
      "2048\n",
      "Preprocessing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e19dbfb1e804e70b96f7619fdbf1f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d00333dba314f469f2fa079c4a25564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee7b43274164433bebf27cdfff51b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd449a48eb244cd8a90ec01f0f4c6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce638b84fb414fbc8db29aa38011edb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee66a43db977464dbf7a3f85a6fb03a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Pre-process dataset\n",
    "max_length = get_max_length(base_model)\n",
    "print(max_length)\n",
    "\n",
    "train_dataset = preprocess_dataset(tokenizer, max_length, seed, dataset['train'])\n",
    "eval_dataset = preprocess_dataset(tokenizer, max_length, seed, dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fb9c308-b320-4422-8b84-7d1b37dfe0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Training: (800, 5)\n",
      "Validation: (100, 5)\n",
      "Dataset({\n",
      "    features: ['prompt', 'pipeline', 'text', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 800\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {train_dataset.shape}\")\n",
    "print(f\"Validation: {eval_dataset.shape}\")\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfae8413-bd6c-498b-90fb-29acee4ec476",
   "metadata": {},
   "source": [
    "## Setup PEFT for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33857f38-bc6b-4fe9-aff3-e861f9190af5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 262364160\n",
      "all model parameters: 1521392640\n",
      "percentage of trainable model parameters: 17.24%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(base_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dc82acd-03bb-401c-a4e5-673c84876403",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhiForCausalLM(\n",
      "  (model): PhiModel(\n",
      "    (embed_tokens): Embedding(51200, 2560)\n",
      "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x PhiDecoderLayer(\n",
      "        (self_attn): PhiSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "          (rotary_emb): PhiRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): PhiMLP(\n",
      "          (activation_fn): NewGELUActivation()\n",
      "          (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
      "          (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
      "        )\n",
      "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "    (rotary_emb): PhiRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1b0c8ba-3926-4011-a91f-49617ddf5120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=32, #Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        'q_proj',\n",
    "        'k_proj',\n",
    "        'v_proj',\n",
    "        'dense'\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# 1 - Enabling gradient checkpointing to reduce memory usage during fine-tuning\n",
    "base_model.gradient_checkpointing_enable()\n",
    "\n",
    "# 2 - Using the prepare_model_for_kbit_training method from PEFT\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "peft_model = get_peft_model(base_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b350f87-3d54-40b4-9af4-2e492958285a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 20971520\n",
      "all model parameters: 1542364160\n",
      "percentage of trainable model parameters: 1.36%\n"
     ]
    }
   ],
   "source": [
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4c84857-e317-4069-a4d1-1340a2ba0e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): PhiForCausalLM(\n",
      "      (model): PhiModel(\n",
      "        (embed_tokens): Embedding(51200, 2560)\n",
      "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x PhiDecoderLayer(\n",
      "            (self_attn): PhiSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (dense): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): PhiRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): PhiMLP(\n",
      "              (activation_fn): NewGELUActivation()\n",
      "              (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
      "              (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
      "            )\n",
      "            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "        (rotary_emb): PhiRotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(peft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c021a-f253-4396-8857-0c40499e35c0",
   "metadata": {},
   "source": [
    "## Train PEFT Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5c4ff27-c411-4ef0-a5fe-187c098fe5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = './peft_GST_pipeline_training_QLora/final-checkpoint'\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    warmup_steps=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    max_steps=100,\n",
    "    learning_rate=2e-4,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    logging_steps=5,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=5,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=5,\n",
    "    do_eval=True,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"none\",\n",
    "    overwrite_output_dir = 'True',\n",
    "    group_by_length=True,\n",
    ")\n",
    "\n",
    "peft_model.config.use_cache = False\n",
    "\n",
    "peft_trainer = transformers.Trainer(\n",
    "    model=peft_model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    args=peft_training_args,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c179ae9-4392-4cb0-95bb-1f3a1930db41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_training_args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f73b5c70-9126-44fa-b06a-f44f6abf9b54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 21:34, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.296200</td>\n",
       "      <td>1.575799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.235000</td>\n",
       "      <td>1.291856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.011300</td>\n",
       "      <td>0.973989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.702366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.707000</td>\n",
       "      <td>0.511820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.547900</td>\n",
       "      <td>0.407002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.440500</td>\n",
       "      <td>0.355748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.413100</td>\n",
       "      <td>0.324753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.354200</td>\n",
       "      <td>0.308422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.321100</td>\n",
       "      <td>0.300194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.279132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.287900</td>\n",
       "      <td>0.270396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.286200</td>\n",
       "      <td>0.261172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.286900</td>\n",
       "      <td>0.251497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.274300</td>\n",
       "      <td>0.248108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.270300</td>\n",
       "      <td>0.245554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.265800</td>\n",
       "      <td>0.244041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>0.243133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.281900</td>\n",
       "      <td>0.242411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>0.242662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.49751404762268064, metrics={'train_runtime': 1302.6041, 'train_samples_per_second': 0.307, 'train_steps_per_second': 0.077, 'total_flos': 3775436910213120.0, 'train_loss': 0.49751404762268064, 'epoch': 0.5})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb3dfe9b-a4cb-474b-83d2-0ea08a623895",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 11077 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "756181d0-2224-4458-a8e0-d5e311593f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'peft_trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_147/322445375.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Free memory for merging weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mpeft_trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'peft_trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# Free memory for merging weights\n",
    "del base_model\n",
    "del peft_trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6827542-e092-4f3d-9e60-617792e38f26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 5469 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881427be-0709-4d58-89b4-4f552446f0c5",
   "metadata": {},
   "source": [
    "##  Evaluate the Model Qualitatively (Human Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5fb02767-fa3a-4d04-9429-5e2262c3139d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b5e3d273544b948112125230453450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                                      device_map='auto',\n",
    "                                                      quantization_config=bnb_config,\n",
    "                                                      trust_remote_code=True,\n",
    "                                                      use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56db492b-7746-45c2-892b-84b13b55ceb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_tokenizer = AutoTokenizer.from_pretrained(model_name, add_bos_token=True, trust_remote_code=True, use_fast=False)\n",
    "eval_tokenizer.pad_token = eval_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "22377089-7b90-4de0-834d-d47fb52f7175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ft_model = PeftModel.from_pretrained(base_model, \"peft_GST_pipeline_training_QLora/final-checkpoint/checkpoint-100\",torch_dtype=torch.float16,is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a5bc8ad-679b-4089-9bae-fe1acfa6a005",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Task: Convert the JSON configuration below into a valid gst-launch-1.0 pipeline command. Ensure all elements and properties are properly formatted.\n",
      "Input JSON:\n",
      "{\"source_type\": \"file\", \"source_location\": \"/opt/warehouse_8/aisle/sensor_3.mp4\", \"video_crop\": {\"top\": 496, \"left\": 71, \"right\": 67, \"bottom\": 129}, \"caps_filter\": \"NV12_16L32S\", \"frame_rate\": \"50/2\", \"detect\": {\"model\": \"/usr/local/models/onnx/detection/3.0/INT8/model_9162.xml\", \"device\": \"HDDL\", \"threshold\": 0.76}, \"track\": {\"tracking_type\": \"zero-term-imageless\"}, \"emit_signals\": false, \"sync\": false, \"drop\": true}\n",
      "Output:\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "GROUND TRUTH:\n",
      "gst-launch-1.0 filesrc location=/opt/warehouse_8/aisle/sensor_3.mp4 ! decodebin ! videoconvert ! videorate ! video/x-raw,framerate=50/2 ! videoconvert ! capsfilter caps=video/x-raw,format=NV12_16L32S ! videocrop top=496 left=71 right=67 bottom=129 ! queue ! gvadetect model=/usr/local/models/onnx/detection/3.0/INT8/model_9162.xml device=HDDL threshold=0.76 ! queue ! gvatrack tracking-type=zero-term-imageless ! queue ! appsink name=appsink emit-signals=False drop=True sync=False\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "gst-launch-1.0 filesrc location=/opt/warehouse_8/aisle/sensor_3.mp4! decodebin! videoconvert! videorate! video/x-raw,framerate=50/2! videocrop top=496 left=71 right=67 bottom=129! queue! videosink! capsfilter caps=video/x-raw,format=NV12_16L32S! queue! gvadetect model=/usr/local/models/onnx/detection/3.0/INT8/model_9162.xml device=HDDL threshold=0.76! queue! gvatrack tracking-type=zero-term-imageless! queue! appsink name=appsink emit-signals=False drop=True sync=False\n",
      "\n",
      "CPU times: user 10.7 s, sys: 19.4 ms, total: 10.7 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "index = 10\n",
    "\n",
    "sample_prompt = dataset['test'][index]['prompt']\n",
    "sample_pipeline = dataset['test'][index]['pipeline']\n",
    "\n",
    "formatted_prompt = get_formatted_prompt(sample_prompt)\n",
    "\n",
    "peft_model_res = generate_text_from_model(ft_model,formatted_prompt)\n",
    "peft_model_output = peft_model_res[0].split('Output:\\n')[1]\n",
    "prefix, success, result = peft_model_output.partition('#End')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{formatted_prompt}\\n')\n",
    "print(dash_line)\n",
    "print(f'GROUND TRUTH:\\n{sample_pipeline}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5762d63e-c5d1-4b33-a03f-6c68e3791eec",
   "metadata": {},
   "source": [
    "## Evaluate the Model Quantitatively (with ROUGE Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "65d5d1a8-498b-42cc-aaa8-28d92e5119d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fa9348fb4547d08276254267003df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                                      device_map='auto',\n",
    "                                                      quantization_config=bnb_config,\n",
    "                                                      trust_remote_code=True,\n",
    "                                                      use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "54edb129-6bd3-48cf-9375-d15f00128d73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompts = dataset['test'][0:10]['prompt']\n",
    "target_pipelines = dataset['test'][0:10]['pipeline']\n",
    "\n",
    "base_model_pipelines = []\n",
    "peft_model_pipelines = []\n",
    "\n",
    "for idx, prompt in enumerate(prompts):\n",
    "    target_text_output = target_pipelines[idx]\n",
    "    formatted_prompt = get_formatted_prompt(prompt)\n",
    "    \n",
    "    base_model_res = generate_text_from_model(base_model,formatted_prompt)\n",
    "    base_model_text_output = base_model_res[0].split('Output:\\n')[1]\n",
    "    \n",
    "    peft_model_res = generate_text_from_model(ft_model,formatted_prompt)\n",
    "    peft_model_output = peft_model_res[0].split('Output:\\n')[1]\n",
    "\n",
    "    peft_model_text_output, success, result = peft_model_output.partition('#End')\n",
    "    \n",
    "\n",
    "    base_model_pipelines.append(base_model_text_output)\n",
    "    peft_model_pipelines.append(peft_model_text_output)\n",
    "\n",
    "zipped_pipelines = list(zip(target_pipelines, base_model_pipelines, peft_model_pipelines))\n",
    " \n",
    "df = pd.DataFrame(zipped_pipelines, columns = ['target_pipelines', 'base_model_pipelines', 'peft_model_pipelines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "81ed4812-d273-46a1-9d8f-b73fd7e2cc07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_pipelines</th>\n",
       "      <th>base_model_pipelines</th>\n",
       "      <th>peft_model_pipelines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gst-launch-1.0 rtspsrc location=rtsp://192.168...</td>\n",
       "      <td>gst-launch-1.0 -s source_type=rtsp -s source_l...</td>\n",
       "      <td>gst-launch-1.0 rtspsrc location=rtsp://192.168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gst-launch-1.0 filesrc location=/opt/retail/sh...</td>\n",
       "      <td>gst-launch-1.0 -source_type file -source_locat...</td>\n",
       "      <td>gst-launch-1.0 filesrc location=/opt/retail/sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gst-launch-1.0 rtspsrc location=rtsp://192.168...</td>\n",
       "      <td>gst-launch-1.0 -s source_type=rtsp -s source_l...</td>\n",
       "      <td>gst-launch-1.0 rtspsrc location=rtsp://192.168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gst-launch-1.0 filesrc location=/opt/mall_6/ai...</td>\n",
       "      <td>gst-launch-1.0 -source_type file -source_locat...</td>\n",
       "      <td>gst-launch-1.0 filesrc location=/opt/mall_6/ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gst-launch-1.0 filesrc location=/opt/data/shop...</td>\n",
       "      <td>gst-launch-1.0 -s source_type=file -s source_l...</td>\n",
       "      <td>gst-launch-1.0 filesrc location=/opt/data/shop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gst-launch-1.0 filesrc location=/opt/data/shop...</td>\n",
       "      <td>gst-launch-1.0 -s source_type=file -s source_l...</td>\n",
       "      <td>gst-launch-1.0 filesrc location=/opt/data/shop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gst-launch-1.0 filesrc location=/opt/shop_8/ai...</td>\n",
       "      <td>gst-launch-1.0 -s source_type=file -s source_l...</td>\n",
       "      <td>gst-launch-1.0 filesrc location=/opt/shop_8/ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gst-launch-1.0 rtspsrc location=rtsp://192.168...</td>\n",
       "      <td>gst-launch-1.0 -s source_type=rtsp -s source_l...</td>\n",
       "      <td>gst-launch-1.0 rtspsrc location=rtsp://192.168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gst-launch-1.0 filesrc location=/opt/data/reta...</td>\n",
       "      <td>gst-launch-1.0 -s source_type=file -s source_l...</td>\n",
       "      <td>gst-launch-1.0 filesrc location=/opt/data/reta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gst-launch-1.0 filesrc location=/opt/data/reta...</td>\n",
       "      <td>gst-launch-1.0 -s source_type=file -s source_l...</td>\n",
       "      <td>gst-launch-1.0 filesrc location=/opt/data/reta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    target_pipelines  \\\n",
       "0  gst-launch-1.0 rtspsrc location=rtsp://192.168...   \n",
       "1  gst-launch-1.0 filesrc location=/opt/retail/sh...   \n",
       "2  gst-launch-1.0 rtspsrc location=rtsp://192.168...   \n",
       "3  gst-launch-1.0 filesrc location=/opt/mall_6/ai...   \n",
       "4  gst-launch-1.0 filesrc location=/opt/data/shop...   \n",
       "5  gst-launch-1.0 filesrc location=/opt/data/shop...   \n",
       "6  gst-launch-1.0 filesrc location=/opt/shop_8/ai...   \n",
       "7  gst-launch-1.0 rtspsrc location=rtsp://192.168...   \n",
       "8  gst-launch-1.0 filesrc location=/opt/data/reta...   \n",
       "9  gst-launch-1.0 filesrc location=/opt/data/reta...   \n",
       "\n",
       "                                base_model_pipelines  \\\n",
       "0  gst-launch-1.0 -s source_type=rtsp -s source_l...   \n",
       "1  gst-launch-1.0 -source_type file -source_locat...   \n",
       "2  gst-launch-1.0 -s source_type=rtsp -s source_l...   \n",
       "3  gst-launch-1.0 -source_type file -source_locat...   \n",
       "4  gst-launch-1.0 -s source_type=file -s source_l...   \n",
       "5  gst-launch-1.0 -s source_type=file -s source_l...   \n",
       "6  gst-launch-1.0 -s source_type=file -s source_l...   \n",
       "7  gst-launch-1.0 -s source_type=rtsp -s source_l...   \n",
       "8  gst-launch-1.0 -s source_type=file -s source_l...   \n",
       "9  gst-launch-1.0 -s source_type=file -s source_l...   \n",
       "\n",
       "                                peft_model_pipelines  \n",
       "0  gst-launch-1.0 rtspsrc location=rtsp://192.168...  \n",
       "1  gst-launch-1.0 filesrc location=/opt/retail/sh...  \n",
       "2  gst-launch-1.0 rtspsrc location=rtsp://192.168...  \n",
       "3  gst-launch-1.0 filesrc location=/opt/mall_6/ai...  \n",
       "4  gst-launch-1.0 filesrc location=/opt/data/shop...  \n",
       "5  gst-launch-1.0 filesrc location=/opt/data/shop...  \n",
       "6  gst-launch-1.0 filesrc location=/opt/shop_8/ai...  \n",
       "7  gst-launch-1.0 rtspsrc location=rtsp://192.168...  \n",
       "8  gst-launch-1.0 filesrc location=/opt/data/reta...  \n",
       "9  gst-launch-1.0 filesrc location=/opt/data/reta...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dc905066-376d-4168-93fd-3150fdf4799f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': np.float64(0.738271826036321), 'rouge2': np.float64(0.6168275504132683), 'rougeL': np.float64(0.6990100149374439), 'rougeLsum': np.float64(0.6964834392441597)}\n",
      "PEFT MODEL:\n",
      "{'rouge1': np.float64(0.9778220179858674), 'rouge2': np.float64(0.9685361200048618), 'rougeL': np.float64(0.9727569471257282), 'rougeLsum': np.float64(0.9734316296669598)}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "base_model_results = rouge.compute(\n",
    "    predictions=base_model_pipelines,\n",
    "    references=target_pipelines[0:len(base_model_pipelines)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "peft_model_results = rouge.compute(\n",
    "    predictions=peft_model_pipelines,\n",
    "    references=target_pipelines[0:len(peft_model_pipelines)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(base_model_results)\n",
    "print('PEFT MODEL:')\n",
    "print(peft_model_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7683d1ae-cf40-4e02-b6fa-1b4e5d69352f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute percentage improvement of PEFT MODEL over ORIGINAL MODEL\n",
      "rouge1: 23.96%\n",
      "rouge2: 35.17%\n",
      "rougeL: 27.37%\n",
      "rougeLsum: 27.69%\n"
     ]
    }
   ],
   "source": [
    "print(\"Absolute percentage improvement of PEFT MODEL over ORIGINAL MODEL\")\n",
    "\n",
    "improvement = (np.array(list(peft_model_results.values())) - np.array(list(base_model_results.values())))\n",
    "for key, value in zip(peft_model_results.keys(), improvement):\n",
    "    print(f'{key}: {value*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9fa71548-e14f-458d-8dd4-428a1080ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"peft_results.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-default:Python",
   "language": "python",
   "name": "conda-env-.conda-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
